{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca59c410-e7ee-4715-904e-32a7cec45bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the semtui package \n",
    "import semtui_refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601a1ea3-2d4f-4818-bdd6-863cc3331d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary classes and functions from the semtui_refactored package\n",
    "from semtui_refactored.data_handler import DataHandler\n",
    "from semtui_refactored.token_manager import TokenManager\n",
    "from semtui_refactored.extension_manager import ExtensionManager\n",
    "from semtui_refactored.reconciliation_manager import ReconciliationManager\n",
    "from semtui_refactored.utils import Utility\n",
    "from semtui_refactored.dataset_manager import DatasetManager\n",
    "from semtui_refactored.semtui_evals import EvaluationManager\n",
    "from semtui_refactored.data_modifier import DataModifier\n",
    "\n",
    "\n",
    "# Set up the API URL and credentials\n",
    "api_url = \"http://localhost:3003/api/\"  # The base URL for the API\n",
    "username = \"test\"  # Username for authentication\n",
    "password = \"test\"  # Password for authentication\n",
    "\n",
    "# Initialize TokenManager\n",
    "signin_data = {\"username\": username, \"password\": password}  # Payload for sign-in request\n",
    "signin_headers = {\n",
    "    \"accept\": \"application/json\",  # Specify the response format\n",
    "    \"content-type\": \"application/json\"  # Specify the request content type\n",
    "}\n",
    "token_manager = TokenManager(api_url, signin_data, signin_headers)  # Create an instance of TokenManager\n",
    "\n",
    "# Get token\n",
    "token = token_manager.get_token()  # Retrieve the authentication token\n",
    "#print(f\"Token: {token}\")  # Uncomment to print the token (useful for debugging)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805fe6cc-54a5-4a26-be77-3ac6b5bd8fe1",
   "metadata": {},
   "source": [
    "# Initialization of Managers\n",
    "\n",
    "This segment of code initializes various manager classes needed for handling data operations, reconciliation, dataset management, evaluations, and extensions. Each manager class is configured with the necessary API URL and authentication token.\n",
    "\n",
    "### Code Explanation\n",
    "- Initialize the `DataManager` for handling data-related operations.\n",
    "- Initialize the `ReconciliationManager` for managing data reconciliation tasks.\n",
    "- Initialize the `DatasetManager` for managing datasets.\n",
    "- Initialize the `EvaluationManager` for handling evaluations.\n",
    "- Initialize the `ExtensionManager` for managing extensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b24162-8f87-4ef1-93da-0851b0fcbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize ReconciliationManager\n",
    "reconciliation_manager = ReconciliationManager(api_url, token_manager)  # Create an instance of ReconciliationManager with API URL and token manager\n",
    "\n",
    "# Initialize DatasetManager\n",
    "dataset_manager = DatasetManager(api_url, token_manager)  # Create an instance of DatasetManager with API URL and token manager\n",
    "\n",
    "# Initialize the EvaluationManager\n",
    "evaluation_manager = EvaluationManager()  # Create an instance of EvaluationManager\n",
    "\n",
    "# Initialize ExtensionManager\n",
    "extension_manager = ExtensionManager(api_url, token)  # Create an instance of ExtensionManager with API URL and token\n",
    "\n",
    "# Initialize the DataModifier\n",
    "data_modifier_manager = DataModifier()  # Create an instance of EvaluationManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5d6682-23c8-4fbf-937d-96974b85b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750e67fb-2517-47ce-9e54-e9f33506427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Pandas Display Options\n",
    "\n",
    "#This segment of code configures the display options for Pandas DataFrames. \n",
    "#Adjusting these settings allows for better visibility and control over how DataFrames are presented in the notebook.\n",
    "\n",
    "### Code Explanation\n",
    "#- Import the Pandas library.\n",
    "#- Set the display option to show all columns of a DataFrame.\n",
    "#- Limit the display to show only the first 20 rows of a DataFrame.\n",
    "    \n",
    "import pandas as pd \n",
    "# Set pandas display options\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_rows', 20)  # Limit to 20 rows for display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ded8c-d3c8-478e-8d91-64c51442ae9b",
   "metadata": {},
   "source": [
    "# Importing and Displaying CSV Data\n",
    "\n",
    "This segment of code handles the importation of data from a CSV file using the `DataManager` class. It reads the CSV file into a Pandas DataFrame and displays the first few rows. Error handling is included to catch and report any issues that arise during the import process.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the path to the CSV file.\n",
    "- Attempt to read the CSV file using the `DataManager` and store it in a DataFrame.\n",
    "- Print a success message and display the first few rows of the DataFrame.\n",
    "- Catch and print any errors that occur during the CSV import.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01c9c25-1f4d-4ef9-9ea6-ee66fc3f295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/abubakarialidu/Documents/SEMT-py/semtui1.1/semtui_refactored\n",
      "CSV file imported successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha_id</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Impresiones</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230101</td>\n",
       "      <td>alquiler pisos colindres</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Community of Madrid</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230101</td>\n",
       "      <td>alquiler pisos sestao</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Catalonia</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230101</td>\n",
       "      <td>steelcraft pedal car</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fecha_id                   Keyword  Impresiones  Clicks       City  \\\n",
       "0  20230101  alquiler pisos colindres            1       0     Madrid   \n",
       "1  20230101     alquiler pisos sestao            1       0  Barcelona   \n",
       "2  20230101      steelcraft pedal car            1       0    Buffalo   \n",
       "\n",
       "                County        Country  \n",
       "0  Community of Madrid          Spain  \n",
       "1            Catalonia          Spain  \n",
       "2             New York  United States  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = \"/Users/abubakarialidu/Documents/Semtui_test/JOT data tutorial notebook tiny.csv\"  # Define the path to the CSV file\n",
    "\n",
    "# Read CSV data using DataManager\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)  # Read the CSV file into a DataFrame using DataManager\n",
    "    print(\"CSV file imported successfully!\")  # Print success message\n",
    "    display(df.head())  # Display the first few rows of the DataFrame\n",
    "except Exception as e:\n",
    "    print(f\"Error importing CSV file: {e}\")  # Print error message if CSV import fails\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae4cd74-7d67-45ad-848b-5d9aeb0c5ec5",
   "metadata": {},
   "source": [
    "# Processing DataFrame for Date Conversion\n",
    "\n",
    "This segment of code processes the DataFrame to convert the 'Fecha_id' column to ISO date format using the `DataManager` class. It includes error handling to manage any issues that arise during the data processing.\n",
    "\n",
    "### Code Explanation\n",
    "- Attempt to process the DataFrame to convert the 'Fecha_id' column to ISO format.\n",
    "- Print a success message and display the first few rows of the processed DataFrame.\n",
    "- Catch and print any errors that occur during the data processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a6c937a-684a-414a-8c33-bb3e28f01a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame modification successful!\n"
     ]
    }
   ],
   "source": [
    "# Use DataModifier to modify the DataFrame\n",
    "try:\n",
    "    # Convert the 'Fecha_id' column to ISO date format\n",
    "    df = DataModifier.iso_date(df, date_col='Fecha_id')\n",
    "\n",
    "    # Uncomment the following lines if you need to perform the respective operations\n",
    "\n",
    "    # df = DataModifier.lower_case(df, column='column_name')  # Convert column values to lowercase\n",
    "    # df = DataModifier.drop_na(df)  # Remove rows with missing values\n",
    "    # df = DataModifier.rename_columns(df, column_rename_dict={'old_name': 'new_name'})  # Rename columns\n",
    "    # df = DataModifier.convert_dtypes(df, dtype_dict={'column_name': 'int'})  # Convert column data types\n",
    "    # df = DataModifier.reorder_columns(df, new_column_order=['col1', 'col2', 'col3'])  # Reorder columns\n",
    "\n",
    "    print(\"DataFrame modification successful!\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69149af-6e7b-4169-afa7-4e51f02e02c0",
   "metadata": {},
   "source": [
    "# Creating and Uploading a Zip File from the Processed DataFrame\n",
    "\n",
    "This segment of code demonstrates how to create a zip file from a processed DataFrame and upload it to a server. It uses utility functions to zip the DataFrame and the `DatasetManager` class to upload the dataset. Error handling is included to manage any issues during these processes.\n",
    "\n",
    "### Code Explanation\n",
    "- Create a zip file from the processed DataFrame.\n",
    "- Print the path of the created zip file.\n",
    "- Attempt to upload the zip file as a dataset to the server.\n",
    "- Print success or failure messages based on the upload result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1174701-6181-42a2-99a1-cbcf003e6997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Create a zip file from the processed DataFrame\\ntry:\\n    zip_filename = \\'processed_dataset.zip\\'  # Define the name for the zip file\\n    zip_path = Utility.create_zip_file(processed_df, zip_filename)  # Create a zip file from the processed DataFrame\\n    print(f\"Zip file created at: {zip_path}\")  # Print the path of the created zip file\\nexcept Exception as e:\\n    print(f\"Error creating zip file: {e}\")  # Print error message if zip file creation fails\\n\\n# Add the dataset to the server\\ndataset_name = \"Processed Dataset\"  # Define the name for the dataset\\ntry:\\n    success, result = dataset_manager.add_dataset(zip_path, dataset_name)  # Attempt to add the dataset to the server\\n    if success:\\n        print(f\"Dataset added successfully with ID: {result}\")  # Print success message with dataset ID\\n    else:\\n        print(f\"Failed to add dataset: {result}\")  # Print failure message with result details\\nexcept Exception as e:\\n    print(f\"Error adding dataset: {e}\")  # Print error message if dataset addition fails\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Create a zip file from the processed DataFrame\n",
    "try:\n",
    "    zip_filename = 'processed_dataset.zip'  # Define the name for the zip file\n",
    "    zip_path = Utility.create_zip_file(processed_df, zip_filename)  # Create a zip file from the processed DataFrame\n",
    "    print(f\"Zip file created at: {zip_path}\")  # Print the path of the created zip file\n",
    "except Exception as e:\n",
    "    print(f\"Error creating zip file: {e}\")  # Print error message if zip file creation fails\n",
    "\n",
    "# Add the dataset to the server\n",
    "dataset_name = \"Processed Dataset\"  # Define the name for the dataset\n",
    "try:\n",
    "    success, result = dataset_manager.add_dataset(zip_path, dataset_name)  # Attempt to add the dataset to the server\n",
    "    if success:\n",
    "        print(f\"Dataset added successfully with ID: {result}\")  # Print success message with dataset ID\n",
    "    else:\n",
    "        print(f\"Failed to add dataset: {result}\")  # Print failure message with result details\n",
    "except Exception as e:\n",
    "    print(f\"Error adding dataset: {e}\")  # Print error message if dataset addition fails\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c30d753-39e5-4700-a10e-949b6d954ea4",
   "metadata": {},
   "source": [
    "# Retrieving and Displaying the List of Datasets\n",
    "\n",
    "This segment of code retrieves the list of datasets from the server using the `DatasetManager` class. It then displays the retrieved datasets in a DataFrame format. Error handling is included to manage any issues during the retrieval process.\n",
    "\n",
    "### Code Explanation\n",
    "- Attempt to retrieve the list of datasets using the `DatasetManager`.\n",
    "- Print a success message and display the DataFrame if datasets are retrieved successfully.\n",
    "- Print a failure message if the retrieval fails.\n",
    "- Catch and print any errors that occur during the retrieval process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "694587ac-a92b-4822-84e9-02166c626022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets retrieved successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userId</th>\n",
       "      <th>name</th>\n",
       "      <th>nTables</th>\n",
       "      <th>lastModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Museums</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-11-06T10:34:36.196Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JOT BC</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-11-06T13:11:29.481Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>SN BC</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-11-15T09:51:35.102Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>InterTwino</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-12-15T13:31:24.769Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>JOT_May2</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-05-06T09:34:53.132Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>JOT_data_Updated</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-05-13T16:07:21.307Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>New_JOT_Update</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-17T10:33:20.178Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>All_Cases</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-05-29T11:07:13.489Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>JOT_data_Updated</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-05-20T15:55:08.590Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>JOT_Tutorial</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-05-22T13:09:13.192Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-23T16:13:41.564Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>Processed Dataset</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-06-05T13:32:51.896Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  userId               name  nTables          lastModifiedDate\n",
       "0    0       0            Museums        6  2023-11-06T10:34:36.196Z\n",
       "1    1       0             JOT BC        7  2023-11-06T13:11:29.481Z\n",
       "2    2       0              SN BC        8  2023-11-15T09:51:35.102Z\n",
       "3    3       0         InterTwino        7  2023-12-15T13:31:24.769Z\n",
       "4   13       0           JOT_May2        3  2024-05-06T09:34:53.132Z\n",
       "5   19       0   JOT_data_Updated        1  2024-05-13T16:07:21.307Z\n",
       "6   20       0     New_JOT_Update        2  2024-05-17T10:33:20.178Z\n",
       "7   21       0          All_Cases       10  2024-05-29T11:07:13.489Z\n",
       "8   22       0   JOT_data_Updated        1  2024-05-20T15:55:08.590Z\n",
       "9   28       0       JOT_Tutorial        4  2024-05-22T13:09:13.192Z\n",
       "10  29       0               test        2  2024-05-23T16:13:41.564Z\n",
       "11  30       0  Processed Dataset        9  2024-06-05T13:32:51.896Z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the list of datasets\n",
    "try:\n",
    "    df_datasets = dataset_manager.get_database_list()  # Retrieve the list of datasets\n",
    "    if df_datasets is not None:\n",
    "        print(\"Datasets retrieved successfully!\")  # Print success message\n",
    "        display(df_datasets)  # Display the DataFrame containing the datasets\n",
    "    else:\n",
    "        print(\"Failed to retrieve datasets.\")  # Print failure message if no datasets are retrieved\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving datasets: {e}\")  # Print error message if dataset retrieval fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4337c-7048-4405-8a53-a37c7e6611ff",
   "metadata": {},
   "source": [
    "# Adding a Table to a Dataset\n",
    "\n",
    "This segment of code demonstrates how to add a table to an existing dataset on the server using the `DatasetManager` class. It specifies the dataset ID and table name, then attempts to add the DataFrame as a table to the specified dataset. Error handling is included to manage any issues that arise during this process.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the dataset ID and table name.\n",
    "- Attempt to add the DataFrame as a table to the specified dataset using the `DatasetManager`.\n",
    "- Catch and print any errors that occur during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85376d9b-d793-4b96-9593-9e13e70b95dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table added successfully!\n",
      "New table added: ID: 148, Name: Jot_test1\n",
      "Table 'Jot_test1' added to dataset ID 30 successfully.\n"
     ]
    }
   ],
   "source": [
    "# Add the table to the dataset\n",
    "dataset_id = \"30\"  # Replace with the actual dataset ID\n",
    "table_name = \"Jot_test1\"  # Define the name of the new table to add\n",
    "\n",
    "try:\n",
    "    dataset_manager.add_table_to_dataset(dataset_id, df, table_name)  # Attempt to add the DataFrame as a table to the dataset\n",
    "    print(f\"Table '{table_name}' added to dataset ID {dataset_id} successfully.\")  # Print success message\n",
    "except Exception as e:\n",
    "    print(f\"Error adding table to dataset: {e}\")  # Print error message if adding table fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0e326-0966-4fe3-9bc4-eae90a608674",
   "metadata": {},
   "source": [
    "# Listing Tables in a Dataset\n",
    "\n",
    "This segment of code retrieves and lists the tables within a specified dataset using the `DatasetManager` class. It specifies the dataset ID and attempts to retrieve the list of tables. Error handling is included to manage any issues that arise during this process.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the dataset ID.\n",
    "- Attempt to list the tables in the specified dataset using the `DatasetManager`.\n",
    "- Catch and print any errors that occur during the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c3c50c8-7ae7-4b39-9587-a105e53238ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in dataset 30:\n",
      "ID: 139, Name: New_JOT_tiny_3\n",
      "ID: 140, Name: New_JOT_tiny_3\n",
      "ID: 141, Name: New_JOT_tiny_3\n",
      "ID: 142, Name: New_JOT_tiny_3\n",
      "ID: 143, Name: New_JOT_tiny_3\n",
      "ID: 144, Name: New_JOT_tiny_3\n",
      "ID: 145, Name: New_JOT_tiny_3\n",
      "ID: 146, Name: New_JOT_tiny_3\n",
      "ID: 147, Name: New_JOT_tiny_3\n",
      "ID: 148, Name: Jot_test1\n"
     ]
    }
   ],
   "source": [
    "# List tables in the dataset\n",
    "dataset_id = \"30\"  # Replace with the actual dataset ID\n",
    "\n",
    "try:\n",
    "    dataset_manager.list_tables_in_dataset(dataset_id) # Attempt to list the tables in the dataset\n",
    "except Exception as e:\n",
    "    print(f\"Error listing tables in dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0629d90-26eb-44e6-995b-c03e262fd0e1",
   "metadata": {},
   "source": [
    "# Deleting a Table from a Dataset\n",
    "\n",
    "This segment of code demonstrates how to delete a specific table from an existing dataset on the server using the `DatasetManager` class. It specifies the dataset ID and the table name to be deleted, then attempts to remove the table. Error handling is included to manage any issues that arise during this process.\n",
    "\n",
    "> **⚠️ Warning:**\n",
    "> Deleting a table is a permanent action and cannot be undone. Ensure that you have verified the table name and dataset ID before performing this operation.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the dataset ID and the table name to be deleted.\n",
    "- Attempt to delete the specified table from the dataset using the `DatasetManager`.\n",
    "- Catch and print any errors that occur during the deletion process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07c13624-47f9-4089-8d4b-dd41a5f7efa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Delete a table from the dataset\\ntable_name_to_delete = \"New_Table2\"  # Replace with the actual table name\\ntry:\\n    dataset_manager.delete_table(dataset_id, table_name_to_delete)\\nexcept Exception as e:\\n    print(f\"Error deleting table: {e}\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Delete a table from the dataset\n",
    "table_name_to_delete = \"New_Table2\"  # Replace with the actual table name\n",
    "\n",
    "try:\n",
    "    dataset_manager.delete_table(dataset_id, table_name_to_delete)  # Attempt to delete the specified table from the dataset\n",
    "    print(f\"Table '{table_name_to_delete}' deleted successfully from dataset ID {dataset_id}.\")  # Print success message\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting table: {e}\")  # Print error message if deleting the table fails\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697db53-3463-40a7-b567-ad53d8bd5644",
   "metadata": {},
   "source": [
    "# Deleting a Dataset\n",
    "\n",
    "This segment of code demonstrates how to delete an entire dataset from the server using the `DatasetManager` class. It specifies the dataset ID and attempts to remove the dataset. Error handling is included to manage any issues that arise during this process.\n",
    "\n",
    "> **⚠️ Warning:**\n",
    "> Deleting a dataset is a permanent action and cannot be undone. Ensure that you have verified the dataset ID before performing this operation.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the dataset ID to be deleted.\n",
    "- Attempt to delete the specified dataset using the `DatasetManager`.\n",
    "- Print the result message from the deletion attempt.\n",
    "- Catch and print any errors that occur during the deletion process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fd68203-4fc1-4026-8ab1-4fd510b58ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Delete the dataset\\ndataset_id = \\'12\\'  # Replace with the actual dataset ID\\n\\ntry:\\n    message = dataset_manager.delete_dataset(dataset_id)  # Attempt to delete the specified dataset\\n    print(message)  # Print the result message\\nexcept Exception as e:\\n    print(f\"Error deleting dataset: {e}\")  # Print error message if deleting the dataset fails\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Delete the dataset\n",
    "dataset_id = '12'  # Replace with the actual dataset ID\n",
    "\n",
    "try:\n",
    "    message = dataset_manager.delete_dataset(dataset_id)  # Attempt to delete the specified dataset\n",
    "    print(message)  # Print the result message\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting dataset: {e}\")  # Print error message if deleting the dataset fails\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecbd0b1-3aae-4cad-a3ad-7d62222fb58d",
   "metadata": {},
   "source": [
    "# Retrieving a Table by Name from a Dataset\n",
    "\n",
    "This segment of code demonstrates how to retrieve a specific table from an existing dataset on the server using the `DatasetManager` class. It specifies the dataset ID and table name, then attempts to fetch the table data. Error handling is included to manage any issues that arise during this process.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the dataset ID and the table name to be retrieved.\n",
    "- Attempt to retrieve the specified table from the dataset using the `DatasetManager`.\n",
    "- Print a success message if the table is retrieved successfully.\n",
    "- Print a failure message if the table is not found in the dataset.\n",
    "- Catch and print any errors that occur during the retrieval process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a8487dc-dc62-4a19-be21-d52ae4ccdd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Jot_test1' retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table_data = dataset_manager.get_table_by_name(dataset_id, table_name)  # Attempt to retrieve the specified table from the dataset\n",
    "    if table_data:\n",
    "        print(f\"Table '{table_name}' retrieved successfully!\")  # Print success message if table is retrieved\n",
    "        # No need to display the DataFrame\n",
    "    else:\n",
    "        print(f\"Table '{table_name}' not found in the dataset.\")  # Print message if table is not found\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving table '{table_name}': {e}\")  # Print error message if retrieving the table fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ddbd2ae-f3c2-42f3-831e-b22b699e2fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#table_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c562752-b27b-4fea-bb58-67a76b2e17c6",
   "metadata": {},
   "source": [
    "# Retrieving the List of Reconciliators\n",
    "\n",
    "This segment of code tests the retrieval of the list of reconciliators using the `ReconciliationManager` class. It attempts to fetch and display the reconciliators in a DataFrame. Error handling is included to manage any issues that arise during the retrieval process.\n",
    "\n",
    "### Code Explanation\n",
    "- Attempt to retrieve the list of reconciliators using the `ReconciliationManager`.\n",
    "- Print a success message and display the DataFrame if reconciliators are retrieved successfully.\n",
    "- Print a failure message if the retrieval fails.\n",
    "- Catch and print any errors that occur during the retrieval process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ed231d-dc64-4d5d-beaf-6838c1cf5922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconciliators retrieved successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>relativeUrl</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geocodingGeonames</td>\n",
       "      <td>/dataset</td>\n",
       "      <td>Geocoding: geo coordinates (GeoNames)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>geocodingHere</td>\n",
       "      <td>/here</td>\n",
       "      <td>Geocoding: geo coordinates (HERE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geonames</td>\n",
       "      <td>/dataset</td>\n",
       "      <td>Linking: GeoNames (GeoNames)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikidataAlligator</td>\n",
       "      <td>/dataset</td>\n",
       "      <td>Linking: Wikidata (Alligator)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikidataOpenRefine</td>\n",
       "      <td>/wikidata</td>\n",
       "      <td>Linking: Wikidata (OpenRefine)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id relativeUrl                                   name\n",
       "0   geocodingGeonames    /dataset  Geocoding: geo coordinates (GeoNames)\n",
       "1       geocodingHere       /here      Geocoding: geo coordinates (HERE)\n",
       "2            geonames    /dataset           Linking: GeoNames (GeoNames)\n",
       "3   wikidataAlligator    /dataset          Linking: Wikidata (Alligator)\n",
       "4  wikidataOpenRefine   /wikidata         Linking: Wikidata (OpenRefine)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test get_reconciliators_list\n",
    "try:\n",
    "    reconciliators_list = reconciliation_manager.get_reconciliators_list()  # Attempt to retrieve the list of reconciliators\n",
    "    if reconciliators_list is not None:\n",
    "        print(\"Reconciliators retrieved successfully!\")  # Print success message\n",
    "        display(reconciliators_list.head())  # Display the first few rows of the DataFrame\n",
    "    else:\n",
    "        print(\"Failed to retrieve reconciliators.\")  # Print failure message if no reconciliators are retrieved\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving reconciliators: {e}\")  # Print error message if retrieving reconciliators fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9521ba-2bec-449b-ae64-f2dc4bfebeac",
   "metadata": {},
   "source": [
    "# Retrieving Parameters for a Specific Reconciliator\n",
    "\n",
    "This segment of code tests the retrieval of parameters for a specific reconciliator using the `ReconciliationManager` class. It specifies the reconciliator ID and attempts to fetch its parameters. The parameters are printed if the retrieval is successful. Error handling is included to manage any issues that arise during the retrieval process.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the ID of the reconciliator.\n",
    "- Attempt to retrieve the parameters for the specified reconciliator using the `ReconciliationManager`.\n",
    "- Print a success message if the parameters are retrieved successfully.\n",
    "- Print a failure message if the retrieval fails.\n",
    "- Catch and print any errors that occur during the retrieval process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe31db2-fff6-4350-b111-8f4aaeb7c6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for reconciliator 'geocodingHere':\n",
      "Mandatory parameters:\n",
      "- table (json): Mandatory\n",
      "  Description: The table data in JSON format\n",
      "- columnName (string): Mandatory\n",
      "  Description: The name of the column to reconcile\n",
      "- idReconciliator (string): Mandatory\n",
      "  Description: The ID of the reconciliator to use\n",
      "\n",
      "Optional parameters:\n",
      "- secondPart (selectColumns): Optional\n",
      "  Description: Optional column to add information to support reconciliation.\n",
      "  Label: Select a column with information about the location to reconcile\n",
      "  Info Text: \n",
      "- thirdPart (selectColumns): Optional\n",
      "  Description: Optional column to add information to support reconciliation.\n",
      "  Label: Select a column with information about the location to reconcile\n",
      "  Info Text: \n",
      "- fourthPart (selectColumns): Optional\n",
      "  Description: Optional column to add information to support reconciliation.\n",
      "  Label: Select a column with information about the location to reconcile\n",
      "  Info Text: \n",
      "Parameters for reconciliator 'geocodingHere' retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test get_reconciliator_parameters\n",
    "id_reconciliator = \"geocodingHere\"  # Replace with the actual reconciliator ID\n",
    "\n",
    "# Get the reconciliator parameters\n",
    "try:\n",
    "    params = reconciliation_manager.get_reconciliator_parameters(id_reconciliator, print_params=True)  # Attempt to retrieve parameters\n",
    "    if params:\n",
    "        print(f\"Parameters for reconciliator '{id_reconciliator}' retrieved successfully!\")  # Print success message\n",
    "    else:\n",
    "        print(f\"Failed to retrieve parameters for reconciliator '{id_reconciliator}'.\")  # Print failure message if retrieval fails\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving parameters for reconciliator '{id_reconciliator}': {e}\")  # Print error message if retrieving parameters fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47f8b9-9534-4c1e-90d4-80da55eff262",
   "metadata": {},
   "source": [
    "# Reconciling a Column in a Table\n",
    "\n",
    "This segment of code tests the reconciliation of a specific column in a table using the `ReconciliationManager` class. It specifies the dataset ID, table name, column name, and reconciliator ID, then attempts to reconcile the column. Error handling is included to manage any issues that arise during the reconciliation process.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the table name and the column name to be reconciled.\n",
    "- Define the ID of the reconciliator.\n",
    "- Attempt to retrieve the table data.\n",
    "- Attempt to reconcile the specified column using the `ReconciliationManager`.\n",
    "- Print a success message if the column is reconciled successfully.\n",
    "- Print a failure message if the reconciliation fails.\n",
    "- Catch and print any errors that occur during the reconciliation process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "520f3315-8d89-478a-8848-1e6aa0e4ec64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column reconciled successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_name = \"City\"  # Define the column name to be reconciled\n",
    "id_reconciliator = \"geocodingHere\"  # Define the ID of the reconciliator\n",
    "\n",
    "\n",
    "# Reconcile the column\n",
    "try:\n",
    "    reconciled_table = reconciliation_manager.reconcile(table_data, column_name, id_reconciliator)  # Attempt to reconcile the specified column\n",
    "    if reconciled_table:\n",
    "        print(\"Column reconciled successfully!\")  # Print success message\n",
    "        # No need to display the table, just print a success message\n",
    "    else:\n",
    "        print(\"Failed to reconcile column.\")  # Print failure message if reconciliation fails\n",
    "except Exception as e:\n",
    "    print(f\"Error reconciling column: {e}\")  # Print error message if reconciliation fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29eac6f-399c-4313-95a6-368f431b4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconciled_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ab21b-6616-49f6-ad94-93fb5b3de39a",
   "metadata": {},
   "source": [
    "# Push reconciliation data to the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab6ee0-d9a0-477b-a2d5-a92d1998fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push reconciliation data to the backend\n",
    "try:\n",
    "    response = reconciliation_manager.push_reconciliation_data_to_backend(dataset_id, table_id, reconciled_data)\n",
    "    if response:\n",
    "        print(\"Reconciliation data pushed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error pushing reconciliation data to the backend: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf139c9-81b0-48ac-ab98-7ffa493f2af6",
   "metadata": {},
   "source": [
    "# Extracting Row Metadata from a Reconciled Table\n",
    "\n",
    "This segment of code demonstrates how to extract metadata for a specific row from a reconciled table using the `EvaluationManager` class. It specifies the reconciled table, the columns of interest, and the row ID, then attempts to extract the metadata for that row. Error handling is included to manage any issues that arise during the extraction process.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the reconciled table data and the list of reconciled columns.\n",
    "- Define the row ID for which metadata is to be extracted.\n",
    "- Attempt to extract metadata for the specified row using the `EvaluationManager`.\n",
    "- Print a success message and the extracted metadata if the extraction is successful.\n",
    "- Catch and print any errors that occur during the extraction process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3933b5-062e-4a7b-b9b0-57062748e630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row metadata extracted successfully!\n",
      "{'City': [{'id': 'georss:41.58339,-81.20288', 'feature': [{'id': 'all_labels', 'value': 100}], 'name': {'value': 'Chardon, OH, United States', 'uri': 'http://www.google.com/maps/place/41.58339,-81.20288'}, 'score': 1, 'match': True, 'type': [{'id': 'wd:Q29934236', 'name': 'GlobeCoordinate'}, {'id': 'georss:point', 'name': 'point'}]}]}\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "reconciled_table = reconciled_table  # Your reconciled table data\n",
    "reconciled_columns = ['City']  # List of reconciled columns\n",
    "row_id = 'r0'  # Replace with the desired row ID\n",
    "\n",
    "# Extract row metadata\n",
    "try:\n",
    "    row_metadata = evaluation_manager.extract_row_metadata(reconciled_table, row_id, reconciled_columns)  # Attempt to extract metadata for the specified row\n",
    "    print(\"Row metadata extracted successfully!\")  # Print success message\n",
    "    print(row_metadata)  # Print the extracted metadata\n",
    "except Exception as e:\n",
    "    print(f\"Error extracting row metadata: {e}\")  # Print error message if metadata extraction fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809d856-c13d-452a-96ee-eeaa54508e1c",
   "metadata": {},
   "source": [
    "# Analyzing Reconciled Data\n",
    "\n",
    "This segment of code performs several analyses on the reconciled table using the `EvaluationManager` class. It counts the number of reconciled cells per column, the number of unique reconciled values per column, and calculates the percentage of reconciled cells per column. The results are printed for each analysis.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the reconciled table and columns of interest.\n",
    "- Count the number of reconciled cells per column.\n",
    "- Count the number of unique reconciled values per column.\n",
    "- Calculate the percentage of reconciled cells per column.\n",
    "- Print the results for each analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f730b64f-3fd3-4938-9776-e15c97659162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconciled cells per column:\n",
      "{'City': 18}\n"
     ]
    }
   ],
   "source": [
    "# Count reconciled cells per column\n",
    "reconciled_cell_counts = evaluation_manager.count_reconciled_cells_per_column(reconciled_table['raw'], reconciled_columns)  # Count reconciled cells\n",
    "print(\"Reconciled cells per column:\")\n",
    "print(reconciled_cell_counts)  # Print the count of reconciled cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ff9598e-99d4-48f2-84cf-c85a11652890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique reconciled values per column:\n",
      "{'City': 86}\n"
     ]
    }
   ],
   "source": [
    "# Count unique reconciled values per column\n",
    "unique_reconciled_values = evaluation_manager.count_unique_reconciled_values_per_column(reconciled_table['raw'], reconciled_columns)  # Count unique reconciled values\n",
    "print(\"Unique reconciled values per column:\")\n",
    "print(unique_reconciled_values)  # Print the count of unique reconciled values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1309e5e8-7303-45d1-8e55-1511cdf0d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of reconciled cells per column:\n",
      "{'City': 100.0}\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of reconciled cells per column\n",
    "reconciled_cell_percentages = evaluation_manager.percentage_reconciled_cells_per_column(reconciled_table['raw'], reconciled_columns)  # Calculate percentage of reconciled cells\n",
    "print(\"Percentage of reconciled cells per column:\")\n",
    "print(reconciled_cell_percentages)  # Print the percentage of reconciled cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adae50e6-b671-49f1-abb8-a46ab5a35dd5",
   "metadata": {},
   "source": [
    "# Retrieving the List of Extenders\n",
    "\n",
    "This segment of code retrieves the list of extenders using the `ExtensionManager` class. It attempts to fetch and display the extenders in a DataFrame. Error handling is included to manage any issues that arise during the retrieval process.\n",
    "\n",
    "### Code Explanation\n",
    "- Attempt to retrieve the list of extenders using the `ExtensionManager`.\n",
    "- Print a success message and display the DataFrame if extenders are retrieved successfully.\n",
    "- Print a failure message if the retrieval fails.\n",
    "- Catch and print any errors that occur during the retrieval process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b65781f-d7e6-4417-b7d4-e865303b9149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extenders retrieved successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>relativeUrl</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geoPropertiesWikidata</td>\n",
       "      <td>/wikidata/entities</td>\n",
       "      <td>Geo Properties (Wikidata)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>geoRouteHere</td>\n",
       "      <td></td>\n",
       "      <td>Geo Route (HERE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meteoPropertiesOpenMeteo</td>\n",
       "      <td></td>\n",
       "      <td>Meteo Properties (OpenMeteo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reconciledColumnExt</td>\n",
       "      <td></td>\n",
       "      <td>Annotation properties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reconciledColumnExtWikidata</td>\n",
       "      <td>/entity/labels</td>\n",
       "      <td>Annotation properties (Wikidata)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id         relativeUrl  \\\n",
       "0        geoPropertiesWikidata  /wikidata/entities   \n",
       "1                 geoRouteHere                       \n",
       "2     meteoPropertiesOpenMeteo                       \n",
       "3          reconciledColumnExt                       \n",
       "4  reconciledColumnExtWikidata      /entity/labels   \n",
       "\n",
       "                               name  \n",
       "0         Geo Properties (Wikidata)  \n",
       "1                  Geo Route (HERE)  \n",
       "2      Meteo Properties (OpenMeteo)  \n",
       "3             Annotation properties  \n",
       "4  Annotation properties (Wikidata)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Extender List\n",
    "try:\n",
    "    extenders_list = extension_manager.get_extenders_list()  # Attempt to retrieve the list of extenders\n",
    "    if extenders_list is not None:\n",
    "        print(\"Extenders retrieved successfully!\")  # Print success message\n",
    "        display(extenders_list.head())  # Display the first few rows of the DataFrame\n",
    "    else:\n",
    "        print(\"Failed to retrieve extenders.\")  # Print failure message if no extenders are retrieved\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving extenders: {e}\")  # Print error message if retrieving extenders fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21380da-00d9-4537-8be7-10327b36e774",
   "metadata": {},
   "source": [
    "# Retrieving Parameters for a Specific Extender\n",
    "\n",
    "This segment of code tests the retrieval of parameters for a specific extender using the `ExtensionManager` class. It specifies the extender ID and attempts to fetch its parameters. The parameters are printed if the retrieval is successful. Error handling is included to manage any issues that arise during the retrieval process.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the ID of the extender.\n",
    "- Attempt to retrieve the parameters for the specified extender using the `ExtensionManager`.\n",
    "- Print a success message if the parameters are retrieved successfully.\n",
    "- Print a failure message if the retrieval fails.\n",
    "- Catch and print any errors that occur during the retrieval process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce10c7d-236d-4753-a9e5-5f30451b50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for extender 'meteoPropertiesOpenMeteo':\n",
      "Mandatory parameters:\n",
      "- dates (selectColumns): Mandatory\n",
      "  Description: Select a column with the days on which to retrieve the weather data:\n",
      "  Label: Select a column with days in ISO8601 format (yyyy-mm-dd)\n",
      "  Info Text: Only dates prior to 10 days are covered (ISO8601 format yyyy-mm-dd)\n",
      "  Options: []\n",
      "\n",
      "- weatherParams (checkbox): Mandatory\n",
      "  Description: Select one or more <b>weather</b> parameters:\n",
      "  Label: Weather parameters\n",
      "  Info Text: Meteo parameters to extend the table\n",
      "  Options: [{'id': 'apparent_temperature_max', 'label': 'Maximum daily apparent temperature in °C', 'value': 'apparent_temperature_max'}, {'id': 'apparent_temperature_min', 'label': 'Minimum daily apparent temperature in °C', 'value': 'apparent_temperature_min'}, {'id': 'precipitation_sum', 'label': 'Sum of daily precipitation (including rain, showers and snowfall) in mm', 'value': 'precipitation_sum'}, {'id': 'precipitation_hours', 'label': 'The number of hours with rain', 'value': 'precipitation_hours'}]\n",
      "\n",
      "Optional parameters:\n",
      "- decimalFormat (checkbox): Optional\n",
      "  Description: Select to change the default period notation (e.g., 12.3):\n",
      "  Label: Decimal format\n",
      "  Info Text: \n",
      "  Options: [{'id': 'format', 'label': 'Use comma as decimal separator (e.g., 12,3)', 'value': 'comma'}]\n",
      "\n",
      "Parameters for extender 'meteoPropertiesOpenMeteo' retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test get_extender_parameters\n",
    "id_extender = \"meteoPropertiesOpenMeteo\"  # Replace with the actual extender ID\n",
    "\n",
    "# Get the extender parameters\n",
    "try:\n",
    "    params = extension_manager.get_extender_parameters(id_extender, print_params=True)  # Attempt to retrieve parameters\n",
    "    if params:\n",
    "        print(f\"Parameters for extender '{id_extender}' retrieved successfully!\")  # Print success message\n",
    "    else:\n",
    "        print(f\"Failed to retrieve parameters for extender '{id_extender}'.\")  # Print failure message if retrieval fails\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving parameters for extender '{id_extender}': {e}\")  # Print error message if retrieving parameters fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c8a3f-5fe2-4d8e-ac24-df835cea7613",
   "metadata": {},
   "source": [
    "# Extending a Column with Additional Properties\n",
    "\n",
    "This segment of code tests the extension of a column in the reconciled table using the `ExtensionManager` class. It specifies the column containing reconciled IDs, the properties to extend, the new column names, the date column, and the extender ID. The properties are added to the DataFrame, creating new columns. Error handling is included to manage any issues that arise during the extension process.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the column containing reconciled IDs.\n",
    "- Specify the properties to be added and their corresponding new column names.\n",
    "- Define the date column name.\n",
    "- Define the ID of the extender.\n",
    "- Attempt to extend the specified column using the `ExtensionManager`.\n",
    "- Print a success message if the column is extended successfully.\n",
    "- Print a failure message if the extension fails.\n",
    "- Catch and print any errors that occur during the extension process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c019f6f-1aab-46b9-8479-56fcafc840a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column extended successfully!\n"
     ]
    }
   ],
   "source": [
    "reconciliated_column_name = 'City'  # Column that contains reconciled IDs\n",
    "properties = [\"apparent_temperature_max\", \"apparent_temperature_min\", \"precipitation_sum\"]  # Replace with actual properties to extend\n",
    "date_column_name = \"Fecha_id\"  # Replace with actual date column name\n",
    "id_extender = \"meteoPropertiesOpenMeteo\"  # ID for Open Meteo Properties extender\n",
    "\n",
    "try:\n",
    "    extended_table = extension_manager.extend_column(\n",
    "        reconciled_table['raw'], \n",
    "        reconciliated_column_name, \n",
    "        id_extender, \n",
    "        properties, \n",
    "        date_column_name=date_column_name,  # Pass date_column_name as a keyword argument\n",
    "        weather_params = properties, \n",
    "        new_columns_name = properties\n",
    "    )  # Attempt to extend the specified column\n",
    "    if extended_table:\n",
    "        print(\"Column extended successfully!\")  # Print success message\n",
    "        # No need to display the table, just print a success message\n",
    "    else:\n",
    "        print(\"Failed to extend column.\")  # Print failure message if extension fails\n",
    "except Exception as e:\n",
    "    print(f\"Error extending column: {e}\")  # Print error message if extending column fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8fe3449-8152-4d1d-a3a2-c876b8cfe7f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table': {'id': '148',\n",
       "  'idDataset': '30',\n",
       "  'name': 'Jot_test1',\n",
       "  'nCols': 7,\n",
       "  'nRows': 3,\n",
       "  'nCells': 21,\n",
       "  'nCellsReconciliated': 0,\n",
       "  'lastModifiedDate': '2024-06-06T07:34:19.790Z'},\n",
       " 'columns': {'Fecha_id': {'id': 'Fecha_id',\n",
       "   'label': 'Fecha_id',\n",
       "   'status': 'empty',\n",
       "   'context': {},\n",
       "   'metadata': []},\n",
       "  'Keyword': {'id': 'Keyword',\n",
       "   'label': 'Keyword',\n",
       "   'status': 'empty',\n",
       "   'context': {},\n",
       "   'metadata': []},\n",
       "  'Impresiones': {'id': 'Impresiones',\n",
       "   'label': 'Impresiones',\n",
       "   'status': 'empty',\n",
       "   'context': {},\n",
       "   'metadata': []},\n",
       "  'Clicks': {'id': 'Clicks',\n",
       "   'label': 'Clicks',\n",
       "   'status': 'empty',\n",
       "   'context': {},\n",
       "   'metadata': []},\n",
       "  'City': {'id': 'City',\n",
       "   'label': 'City',\n",
       "   'status': 'pending',\n",
       "   'context': {'georss': {'uri': 'http://www.google.com/maps/place/',\n",
       "     'total': 3,\n",
       "     'reconciliated': 3}},\n",
       "   'metadata': [{'id': '',\n",
       "     'match': True,\n",
       "     'score': 0,\n",
       "     'name': {'value': '', 'uri': ''},\n",
       "     'entity': [{'id': 'wd:Q29934236',\n",
       "       'name': {'value': 'GlobeCoordinate',\n",
       "        'uri': 'http://www.google.com/maps/place/Q29934236'},\n",
       "       'score': 0,\n",
       "       'match': True,\n",
       "       'type': []},\n",
       "      {'id': 'georss:point',\n",
       "       'name': {'value': 'point',\n",
       "        'uri': 'http://www.google.com/maps/place/point'},\n",
       "       'score': 0,\n",
       "       'match': True,\n",
       "       'type': []}],\n",
       "     'property': [],\n",
       "     'type': [{'id': 'wd:Q29934236', 'name': 'GlobeCoordinate'},\n",
       "      {'id': 'wd:Q29934236', 'name': 'GlobeCoordinate'},\n",
       "      {'id': 'wd:Q29934236', 'name': 'GlobeCoordinate'}]}],\n",
       "   'kind': 'entity',\n",
       "   'annotationMeta': {'annotated': True,\n",
       "    'match': {'value': True},\n",
       "    'lowestScore': 1,\n",
       "    'highestScore': 1}},\n",
       "  'County': {'id': 'County',\n",
       "   'label': 'County',\n",
       "   'status': 'empty',\n",
       "   'context': {},\n",
       "   'metadata': []},\n",
       "  'Country': {'id': 'Country',\n",
       "   'label': 'Country',\n",
       "   'status': 'empty',\n",
       "   'context': {},\n",
       "   'metadata': []}},\n",
       " 'rows': {'r0': {'id': 'r0',\n",
       "   'cells': {'Fecha_id': {'id': 'r0$Fecha_id',\n",
       "     'label': '2023-01-01',\n",
       "     'metadata': []},\n",
       "    'Keyword': {'id': 'r0$Keyword',\n",
       "     'label': 'alquiler pisos colindres',\n",
       "     'metadata': []},\n",
       "    'Impresiones': {'id': 'r0$Impresiones', 'label': '1', 'metadata': []},\n",
       "    'Clicks': {'id': 'r0$Clicks', 'label': '0', 'metadata': []},\n",
       "    'City': {'id': 'r0$City',\n",
       "     'label': 'Madrid',\n",
       "     'metadata': [{'id': 'georss:40.41955,-3.69196',\n",
       "       'feature': [{'id': 'all_labels', 'value': 100}],\n",
       "       'name': {'value': 'Madrid, Community of Madrid, Spain',\n",
       "        'uri': 'http://www.google.com/maps/place/40.41955,-3.69196'},\n",
       "       'score': 1,\n",
       "       'match': True,\n",
       "       'type': [{'id': 'wd:Q29934236', 'name': 'GlobeCoordinate'},\n",
       "        {'id': 'georss:point', 'name': 'point'}]}],\n",
       "     'annotationMeta': {'annotated': True,\n",
       "      'match': {'value': True},\n",
       "      'lowestScore': 1,\n",
       "      'highestScore': 1}},\n",
       "    'County': {'id': 'r0$County',\n",
       "     'label': 'Community of Madrid',\n",
       "     'metadata': []},\n",
       "    'Country': {'id': 'r0$Country', 'label': 'Spain', 'metadata': []},\n",
       "    'apparent_temperature_max': {'id': 'r0$apparent_temperature_max',\n",
       "     'label': '12,7',\n",
       "     'metadata': [],\n",
       "     'annotationMeta': {}},\n",
       "    'apparent_temperature_min': {'id': 'r0$apparent_temperature_min',\n",
       "     'label': '0,8',\n",
       "     'metadata': [],\n",
       "     'annotationMeta': {}},\n",
       "    'precipitation_sum': {'id': 'r0$precipitation_sum',\n",
       "     'label': '0',\n",
       "     'metadata': [],\n",
       "     'annotationMeta': {}}}},\n",
       "  'r1': {'id': 'r1',\n",
       "   'cells': {'Fecha_id': {'id': 'r1$Fecha_id',\n",
       "     'label': '2023-01-01',\n",
       "     'metadata': []},\n",
       "    'Keyword': {'id': 'r1$Keyword',\n",
       "     'label': 'alquiler pisos sestao',\n",
       "     'metadata': []},\n",
       "    'Impresiones': {'id': 'r1$Impresiones', 'label': '1', 'metadata': []},\n",
       "    'Clicks': {'id': 'r1$Clicks', 'label': '0', 'metadata': []},\n",
       "    'City': {'id': 'r1$City',\n",
       "     'label': 'Barcelona',\n",
       "     'metadata': [{'id': 'georss:41.38804,2.17001',\n",
       "       'feature': [{'id': 'all_labels', 'value': 100}],\n",
       "       'name': {'value': 'Barcelona, Catalonia, Spain',\n",
       "        'uri': 'http://www.google.com/maps/place/41.38804,2.17001'},\n",
       "       'score': 1,\n",
       "       'match': True,\n",
       "       'type': [{'id': 'wd:Q29934236', 'name': 'GlobeCoordinate'},\n",
       "        {'id': 'georss:point', 'name': 'point'}]}],\n",
       "     'annotationMeta': {'annotated': True,\n",
       "      'match': {'value': True},\n",
       "      'lowestScore': 1,\n",
       "      'highestScore': 1}},\n",
       "    'County': {'id': 'r1$County', 'label': 'Catalonia', 'metadata': []},\n",
       "    'Country': {'id': 'r1$Country', 'label': 'Spain', 'metadata': []},\n",
       "    'apparent_temperature_max': {'id': 'r1$apparent_temperature_max',\n",
       "     'label': '16,5',\n",
       "     'metadata': [],\n",
       "     'annotationMeta': {}},\n",
       "    'apparent_temperature_min': {'id': 'r1$apparent_temperature_min',\n",
       "     'label': '4,2',\n",
       "     'metadata': [],\n",
       "     'annotationMeta': {}},\n",
       "    'precipitation_sum': {'id': 'r1$precipitation_sum',\n",
       "     'label': '0',\n",
       "     'metadata': [],\n",
       "     'annotationMeta': {}}}},\n",
       "  'r2': {'id': 'r2',\n",
       "   'cells': {'Fecha_id': {'id': 'r2$Fecha_id',\n",
       "     'label': '2023-01-01',\n",
       "     'metadata': []},\n",
       "    'Keyword': {'id': 'r2$Keyword',\n",
       "     'label': 'steelcraft pedal car',\n",
       "     'metadata': []},\n",
       "    'Impresiones': {'id': 'r2$Impresiones', 'label': '1', 'metadata': []},\n",
       "    'Clicks': {'id': 'r2$Clicks', 'label': '0', 'metadata': []},\n",
       "    'City': {'id': 'r2$City',\n",
       "     'label': 'Buffalo',\n",
       "     'metadata': [{'id': 'georss:42.88545,-78.87846',\n",
       "       'feature': [{'id': 'all_labels', 'value': 100}],\n",
       "       'name': {'value': 'Buffalo, NY, United States',\n",
       "        'uri': 'http://www.google.com/maps/place/42.88545,-78.87846'},\n",
       "       'score': 1,\n",
       "       'match': True,\n",
       "       'type': [{'id': 'wd:Q29934236', 'name': 'GlobeCoordinate'},\n",
       "        {'id': 'georss:point', 'name': 'point'}]}],\n",
       "     'annotationMeta': {'annotated': True,\n",
       "      'match': {'value': True},\n",
       "      'lowestScore': 1,\n",
       "      'highestScore': 1}},\n",
       "    'County': {'id': 'r2$County', 'label': 'New York', 'metadata': []},\n",
       "    'Country': {'id': 'r2$Country', 'label': 'United States', 'metadata': []},\n",
       "    'apparent_temperature_max': {'id': 'r2$apparent_temperature_max',\n",
       "     'label': '2,6',\n",
       "     'metadata': [],\n",
       "     'annotationMeta': {}},\n",
       "    'apparent_temperature_min': {'id': 'r2$apparent_temperature_min',\n",
       "     'label': '-2,8',\n",
       "     'metadata': [],\n",
       "     'annotationMeta': {}},\n",
       "    'precipitation_sum': {'id': 'r2$precipitation_sum',\n",
       "     'label': '2,4',\n",
       "     'metadata': [],\n",
       "     'annotationMeta': {}}}}},\n",
       " 'id': '148'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487826cc-fc30-442e-b210-28ce3ca0ea35",
   "metadata": {},
   "source": [
    "# Converting Extended Data to DataFrame\n",
    "\n",
    "This segment of code demonstrates how to convert the extended data returned as a JSON object into a Pandas DataFrame using the `Utility` class. It assumes that the extended data is in JSON format and uses a utility function to load it into a DataFrame. Error handling is included to manage any issues that arise during the conversion process.\n",
    "\n",
    "### Code Explanation\n",
    "- Import the `Utility` class.\n",
    "- Attempt to convert the JSON object containing extended data into a Pandas DataFrame using `Utility.load_json_to_dataframe`.\n",
    "- Print a success message and display the first few rows of the DataFrame if the conversion is successful.\n",
    "- Catch and print any errors that occur during the conversion process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31d836ee-a7d1-402f-9784-eb686398d41c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended data loaded into DataFrame successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha_id</th>\n",
       "      <th>Cuenta_id</th>\n",
       "      <th>Campaña_id</th>\n",
       "      <th>Grupo_id</th>\n",
       "      <th>Keyword_id</th>\n",
       "      <th>City_id</th>\n",
       "      <th>State_id</th>\n",
       "      <th>Country_id</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Impresiones</th>\n",
       "      <th>...</th>\n",
       "      <th>Qs_med</th>\n",
       "      <th>Qs_iqr</th>\n",
       "      <th>Qs_max</th>\n",
       "      <th>Qs_min</th>\n",
       "      <th>Apparent_Max_Temperature</th>\n",
       "      <th>Apparent_Min_Temperature</th>\n",
       "      <th>Total_Precipitation</th>\n",
       "      <th>City URI</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>1018571837</td>\n",
       "      <td>17309187968</td>\n",
       "      <td>138000000000.0</td>\n",
       "      <td>299000000000.0</td>\n",
       "      <td>1023619</td>\n",
       "      <td>21168</td>\n",
       "      <td>2840</td>\n",
       "      <td>5th third bank cd rates</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>29,9</td>\n",
       "      <td>20,3</td>\n",
       "      <td>10,6</td>\n",
       "      <td>http://www.google.com/maps/place/41.58339,-81....</td>\n",
       "      <td>41.58339</td>\n",
       "      <td>-81.20288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>1018571837</td>\n",
       "      <td>17309187968</td>\n",
       "      <td>138000000000.0</td>\n",
       "      <td>299000000000.0</td>\n",
       "      <td>1023631</td>\n",
       "      <td>21168</td>\n",
       "      <td>2840</td>\n",
       "      <td>5th third bank cd rates</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>30,7</td>\n",
       "      <td>22,4</td>\n",
       "      <td>5,1</td>\n",
       "      <td>http://www.google.com/maps/place/41.50473,-81....</td>\n",
       "      <td>41.50473</td>\n",
       "      <td>-81.69074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>1018571837</td>\n",
       "      <td>17309187968</td>\n",
       "      <td>138000000000.0</td>\n",
       "      <td>299000000000.0</td>\n",
       "      <td>1016367</td>\n",
       "      <td>21147</td>\n",
       "      <td>2840</td>\n",
       "      <td>5th third bank cd rates</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>32,4</td>\n",
       "      <td>22,8</td>\n",
       "      <td>16,2</td>\n",
       "      <td>http://www.google.com/maps/place/41.88425,-87....</td>\n",
       "      <td>41.88425</td>\n",
       "      <td>-87.63245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>1018571837</td>\n",
       "      <td>17309187968</td>\n",
       "      <td>138000000000.0</td>\n",
       "      <td>299000000000.0</td>\n",
       "      <td>1027744</td>\n",
       "      <td>21180</td>\n",
       "      <td>2840</td>\n",
       "      <td>5th third bank cd rates</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>11,3</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.google.com/maps/place/47.60357,-122...</td>\n",
       "      <td>47.60357</td>\n",
       "      <td>-122.32945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>1119272776</td>\n",
       "      <td>20325090181</td>\n",
       "      <td>154000000000.0</td>\n",
       "      <td>2240000000000.0</td>\n",
       "      <td>1016359</td>\n",
       "      <td>21147</td>\n",
       "      <td>2840</td>\n",
       "      <td>p n c bank c d rates</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>34,9</td>\n",
       "      <td>23,1</td>\n",
       "      <td>12,2</td>\n",
       "      <td>http://www.google.com/maps/place/40.1142,-88.2435</td>\n",
       "      <td>40.1142</td>\n",
       "      <td>-88.2435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fecha_id   Cuenta_id   Campaña_id        Grupo_id       Keyword_id  \\\n",
       "0  2023-07-01  1018571837  17309187968  138000000000.0   299000000000.0   \n",
       "1  2023-07-01  1018571837  17309187968  138000000000.0   299000000000.0   \n",
       "2  2023-07-01  1018571837  17309187968  138000000000.0   299000000000.0   \n",
       "3  2023-07-01  1018571837  17309187968  138000000000.0   299000000000.0   \n",
       "4  2023-07-01  1119272776  20325090181  154000000000.0  2240000000000.0   \n",
       "\n",
       "   City_id State_id Country_id                  Keyword Impresiones  ...  \\\n",
       "0  1023619    21168       2840  5th third bank cd rates           4  ...   \n",
       "1  1023631    21168       2840  5th third bank cd rates           4  ...   \n",
       "2  1016367    21147       2840  5th third bank cd rates           5  ...   \n",
       "3  1027744    21180       2840  5th third bank cd rates           4  ...   \n",
       "4  1016359    21147       2840     p n c bank c d rates           3  ...   \n",
       "\n",
       "  Qs_med Qs_iqr Qs_max Qs_min Apparent_Max_Temperature  \\\n",
       "0      0      0     10      0                     29,9   \n",
       "1      0      0     10      0                     30,7   \n",
       "2      0      0     10      0                     32,4   \n",
       "3      0      0     10      0                       25   \n",
       "4      0      0     10      0                     34,9   \n",
       "\n",
       "  Apparent_Min_Temperature Total_Precipitation  \\\n",
       "0                     20,3                10,6   \n",
       "1                     22,4                 5,1   \n",
       "2                     22,8                16,2   \n",
       "3                     11,3                   0   \n",
       "4                     23,1                12,2   \n",
       "\n",
       "                                            City URI  Latitude   Longitude  \n",
       "0  http://www.google.com/maps/place/41.58339,-81....  41.58339   -81.20288  \n",
       "1  http://www.google.com/maps/place/41.50473,-81....  41.50473   -81.69074  \n",
       "2  http://www.google.com/maps/place/41.88425,-87....  41.88425   -87.63245  \n",
       "3  http://www.google.com/maps/place/47.60357,-122...  47.60357  -122.32945  \n",
       "4  http://www.google.com/maps/place/40.1142,-88.2435   40.1142    -88.2435  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the Utility class\n",
    "from semtui_refactored.utils import Utility\n",
    "\n",
    "# Assuming extended_table is the JSON object you got from the extend_column method\n",
    "try:\n",
    "    # Convert JSON to DataFrame\n",
    "    extended_df = Utility.load_json_to_dataframe(extended_table, georeference_data=True)  # Load the extended data into a DataFrame\n",
    "    print(\"Extended data loaded into DataFrame successfully!\")  # Print success message\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    display(extended_df.head())  # Display the first few rows of the DataFrame\n",
    "except Exception as e:\n",
    "    print(f\"Error loading extended data into DataFrame: {e}\")  # Print error message if loading into DataFrame fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816eaae5-2c09-4cf7-bdfe-f4f334680121",
   "metadata": {},
   "source": [
    "# Analyzing Extended Data\n",
    "\n",
    "This segment of code performs several analyses on the extended table using the `EvaluationManager` class. It counts the number of extended cells per column, the number of unique extended values per column, and calculates the percentage of extended cells per column. The results are printed for each analysis.\n",
    "\n",
    "### Code Explanation\n",
    "- Define the list of extended columns.\n",
    "- Count the number of extended cells per column.\n",
    "- Count the number of unique extended values per column.\n",
    "- Calculate the percentage of extended cells per column.\n",
    "- Print the results for each analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e313f086-0ee5-466a-a495-95fd9d452199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended cells per column:\n",
      "{'Apparent_Max_Temperature': 18, 'Apparent_Min_Temperature': 18, 'Total_Precipitation': 18}\n"
     ]
    }
   ],
   "source": [
    "# Define the list of extended columns\n",
    "extended_columns = ['Apparent_Max_Temperature', 'Apparent_Min_Temperature', 'Total_Precipitation']\n",
    "\n",
    "# Count extended cells per column\n",
    "extended_cell_counts = evaluation_manager.count_extended_cells_per_column(extended_table, extended_columns)  # Count extended cells\n",
    "print(\"Extended cells per column:\")\n",
    "print(extended_cell_counts)  # Print the count of extended cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0306943-f5ef-4156-9f44-13b3e1083150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique extended values per column:\n",
      "{'Apparent_Max_Temperature': 18, 'Apparent_Min_Temperature': 18, 'Total_Precipitation': 12}\n"
     ]
    }
   ],
   "source": [
    "# Count unique extended values per column\n",
    "unique_extended_values = evaluation_manager.count_unique_extended_values_per_column(extended_table, extended_columns)  # Count unique extended values\n",
    "print(\"Unique extended values per column:\")\n",
    "print(unique_extended_values)  # Print the count of unique extended values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ada7fae4-e6b5-4a00-807b-d85e33d6246a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of extended cells per column:\n",
      "{'Apparent_Max_Temperature': 100.0, 'Apparent_Min_Temperature': 100.0, 'Total_Precipitation': 100.0}\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of extended cells per column\n",
    "extended_cell_percentages = evaluation_manager.percentage_extended_cells_per_column(extended_table, extended_columns)  # Calculate percentage of extended cells\n",
    "print(\"Percentage of extended cells per column:\")\n",
    "print(extended_cell_percentages)  # Print the percentage of extended cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241b6fdc-c95a-44cb-bb33-62e9681533ad",
   "metadata": {},
   "source": [
    "# Download the data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28b0ad7-81ab-42f3-a12b-e90fd01ef0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended data saved to extended_data.csv successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the CSV file path\n",
    "csv_file_path = \"extended_data.csv\"\n",
    "\n",
    "try:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    extended_df.to_csv(csv_file_path, index=False)  # Save DataFrame to CSV\n",
    "    print(f\"Extended data saved to {csv_file_path} successfully!\")  # Print success message for saving CSV\n",
    "except Exception as e:\n",
    "    print(f\"Error saving extended data to CSV: {e}\")  # Print error message if saving to CSV fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3eeca8-b9b6-41d0-98e7-9dee4ec26f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semtui-test)",
   "language": "python",
   "name": "semtui-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
